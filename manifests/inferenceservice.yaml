apiVersion: serving.kserve.io/v1beta1
kind: InferenceService
metadata:
  name: whisperx
  namespace: my-namespace
spec:
  predictor:
    containers:
      - name: kserve-container
        image: quay.io/demo-org/whisperx-kserve:v0.1
        args:
          - --workers=1
          - --http_port=8080
          - --model_name=whisperx
        resources:
          limits:
            cpu: 2
            memory: 4Gi
          requests:
            cpu: 1
            memory: 2Gi
